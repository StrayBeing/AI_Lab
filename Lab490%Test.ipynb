{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiuyhGu+e8llFI9EjlpnlN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StrayBeing/AI_Lab/blob/main/Lab490%25Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "jvZL0I31DBmS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.layers import LeakyReLU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "npz = np.load('Audiobooks_data_train.npz')\n",
        "train_inputs = npz['inputs'].astype(np.float32)\n",
        "train_targets = npz['targets'].astype(np.int32)\n",
        "npz = np.load('Audiobooks_data_validation.npz')\n",
        "validation_inputs, validation_targets = npz['inputs'].astype(np.float32), npz['targets'].astype(np.int32)\n",
        "npz = np.load('Audiobooks_data_test.npz')\n",
        "test_inputs, test_targets = npz['inputs'].astype(np.float32), npz['targets'].astype(np.int32)\n"
      ],
      "metadata": {
        "id": "cQPnuUajDUxF"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 10\n",
        "output_size = 2\n",
        "hidden_layer_size = 100\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(512),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "\n",
        "    tf.keras.layers.Dense(256),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.Dense(128),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.Dense(64),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Nadam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICF375w8D7T-",
        "outputId": "22562434-64c1-4f8b-cb90-71ca98b1a187"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "max_epochs = 100\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_targets),\n",
        "    y=train_targets\n",
        ")\n",
        "\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "model.fit(train_inputs,\n",
        "         train_targets,\n",
        "         batch_size=batch_size,\n",
        "         epochs=max_epochs,\n",
        "         callbacks=[early_stopping],\n",
        "         validation_data=(validation_inputs, validation_targets),\n",
        "          class_weight=class_weights,\n",
        "         verbose=1\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwmPEGRSE-K1",
        "outputId": "26107d2d-241b-4061-eb97-c7cfe86df90e"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.6256 - loss: 0.7869 - val_accuracy: 0.7002 - val_loss: 0.5448\n",
            "Epoch 2/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7399 - loss: 0.4807 - val_accuracy: 0.7718 - val_loss: 0.5131\n",
            "Epoch 3/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7410 - loss: 0.4713 - val_accuracy: 0.6711 - val_loss: 0.5214\n",
            "Epoch 4/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7583 - loss: 0.4473 - val_accuracy: 0.7204 - val_loss: 0.4803\n",
            "Epoch 5/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7466 - loss: 0.4348 - val_accuracy: 0.7830 - val_loss: 0.4421\n",
            "Epoch 6/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7657 - loss: 0.4167 - val_accuracy: 0.7539 - val_loss: 0.4410\n",
            "Epoch 7/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7868 - loss: 0.4009 - val_accuracy: 0.7293 - val_loss: 0.4298\n",
            "Epoch 8/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7804 - loss: 0.3967 - val_accuracy: 0.7539 - val_loss: 0.4204\n",
            "Epoch 9/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7840 - loss: 0.3922 - val_accuracy: 0.7405 - val_loss: 0.4260\n",
            "Epoch 10/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7588 - loss: 0.4134 - val_accuracy: 0.7740 - val_loss: 0.3976\n",
            "Epoch 11/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7689 - loss: 0.4114 - val_accuracy: 0.7852 - val_loss: 0.3860\n",
            "Epoch 12/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7709 - loss: 0.4017 - val_accuracy: 0.7830 - val_loss: 0.3727\n",
            "Epoch 13/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7790 - loss: 0.4002 - val_accuracy: 0.8009 - val_loss: 0.3570\n",
            "Epoch 14/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7858 - loss: 0.3713 - val_accuracy: 0.8076 - val_loss: 0.3545\n",
            "Epoch 15/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7988 - loss: 0.3668 - val_accuracy: 0.8076 - val_loss: 0.3473\n",
            "Epoch 16/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7816 - loss: 0.3864 - val_accuracy: 0.8076 - val_loss: 0.3493\n",
            "Epoch 17/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7896 - loss: 0.3712 - val_accuracy: 0.8098 - val_loss: 0.3569\n",
            "Epoch 18/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7897 - loss: 0.3709 - val_accuracy: 0.8098 - val_loss: 0.3519\n",
            "Epoch 19/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8044 - loss: 0.3602 - val_accuracy: 0.8054 - val_loss: 0.3313\n",
            "Epoch 20/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7916 - loss: 0.3716 - val_accuracy: 0.8076 - val_loss: 0.3383\n",
            "Epoch 21/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7988 - loss: 0.3666 - val_accuracy: 0.8098 - val_loss: 0.3342\n",
            "Epoch 22/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7850 - loss: 0.3775 - val_accuracy: 0.8098 - val_loss: 0.3382\n",
            "Epoch 23/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8045 - loss: 0.3557 - val_accuracy: 0.8076 - val_loss: 0.3406\n",
            "Epoch 24/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8035 - loss: 0.3523 - val_accuracy: 0.8054 - val_loss: 0.3490\n",
            "Epoch 25/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8050 - loss: 0.3624 - val_accuracy: 0.8076 - val_loss: 0.3403\n",
            "Epoch 26/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7970 - loss: 0.3605 - val_accuracy: 0.8098 - val_loss: 0.3437\n",
            "Epoch 27/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8037 - loss: 0.3595 - val_accuracy: 0.8166 - val_loss: 0.3255\n",
            "Epoch 28/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8019 - loss: 0.3612 - val_accuracy: 0.8143 - val_loss: 0.3284\n",
            "Epoch 29/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7932 - loss: 0.3620 - val_accuracy: 0.8098 - val_loss: 0.3284\n",
            "Epoch 30/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8062 - loss: 0.3606 - val_accuracy: 0.8143 - val_loss: 0.3283\n",
            "Epoch 31/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8045 - loss: 0.3528 - val_accuracy: 0.8210 - val_loss: 0.3222\n",
            "Epoch 32/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8099 - loss: 0.3496 - val_accuracy: 0.8143 - val_loss: 0.3261\n",
            "Epoch 33/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8158 - loss: 0.3460 - val_accuracy: 0.8143 - val_loss: 0.3284\n",
            "Epoch 34/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8159 - loss: 0.3506 - val_accuracy: 0.8143 - val_loss: 0.3216\n",
            "Epoch 35/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8072 - loss: 0.3508 - val_accuracy: 0.8210 - val_loss: 0.3200\n",
            "Epoch 36/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8131 - loss: 0.3481 - val_accuracy: 0.8166 - val_loss: 0.3263\n",
            "Epoch 37/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8072 - loss: 0.3523 - val_accuracy: 0.8143 - val_loss: 0.3314\n",
            "Epoch 38/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8015 - loss: 0.3587 - val_accuracy: 0.8166 - val_loss: 0.3250\n",
            "Epoch 39/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8098 - loss: 0.3463 - val_accuracy: 0.8166 - val_loss: 0.3206\n",
            "Epoch 40/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8109 - loss: 0.3431 - val_accuracy: 0.8098 - val_loss: 0.3321\n",
            "Epoch 41/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8131 - loss: 0.3497 - val_accuracy: 0.8166 - val_loss: 0.3299\n",
            "Epoch 42/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8061 - loss: 0.3467 - val_accuracy: 0.8076 - val_loss: 0.3277\n",
            "Epoch 43/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8097 - loss: 0.3528 - val_accuracy: 0.8188 - val_loss: 0.3256\n",
            "Epoch 44/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8170 - loss: 0.3399 - val_accuracy: 0.8255 - val_loss: 0.3341\n",
            "Epoch 45/100\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8097 - loss: 0.3475 - val_accuracy: 0.8233 - val_loss: 0.3236\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78dce9081850>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)\n",
        "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l621W4TWFIlz",
        "outputId": "bdf3405c-e3be-487d-dc64-5d8b558d84fa"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.3907 \n",
            "\n",
            "Test loss: 0.38. Test accuracy: 81.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "viMTHfMWD6xs"
      }
    }
  ]
}