{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaccec4e-7646-40b0-bf3b-8114efa16abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import socket\n",
    "from requests.exceptions import ConnectionError\n",
    "from requests.exceptions import MissingSchema\n",
    "from requests.exceptions import InvalidSchema\n",
    "from urllib3.exceptions import MaxRetryError, NameResolutionError\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e71992e1-cb21-4a11-a6f1-3621f43b97fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "MODEL = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e4494a4-2b9a-42f5-959b-eaccdc571a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \\\n",
    "    (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bac132a9-1c3b-4dfd-b1dd-0206879f7e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/posts',\n",
       " '/docs',\n",
       " '/enterprise',\n",
       " '/pricing',\n",
       " '/login',\n",
       " '/join',\n",
       " '/spaces',\n",
       " '/models',\n",
       " '/nvidia/parakeet-tdt-0.6b-v2',\n",
       " '/ACE-Step/ACE-Step-v1-3.5B',\n",
       " '/Lightricks/LTX-Video',\n",
       " '/nari-labs/Dia-1.6B',\n",
       " '/lodestones/Chroma',\n",
       " '/models',\n",
       " '/spaces/smolagents/computer-agent',\n",
       " '/spaces/enzostvs/deepsite',\n",
       " '/spaces/ByteDance/DreamO',\n",
       " '/spaces/ACE-Step/ACE-Step',\n",
       " '/spaces/NihalGazi/FLUX-Pro-Unlimited',\n",
       " '/spaces',\n",
       " '/datasets/DMindAI/DMind_Benchmark',\n",
       " '/datasets/nvidia/OpenCodeReasoning',\n",
       " '/datasets/nvidia/OpenMathReasoning',\n",
       " '/datasets/nvidia/Nemotron-CrossThink',\n",
       " '/datasets/openbmb/Ultra-FineWeb',\n",
       " '/datasets',\n",
       " '/join',\n",
       " '/pricing#endpoints',\n",
       " '/pricing#spaces',\n",
       " '/pricing',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/allenai',\n",
       " '/facebook',\n",
       " '/amazon',\n",
       " '/google',\n",
       " '/Intel',\n",
       " '/microsoft',\n",
       " '/grammarly',\n",
       " '/Writer',\n",
       " '/docs/transformers',\n",
       " '/docs/diffusers',\n",
       " '/docs/safetensors',\n",
       " '/docs/huggingface_hub',\n",
       " '/docs/tokenizers',\n",
       " '/docs/trl',\n",
       " '/docs/transformers.js',\n",
       " '/docs/smolagents',\n",
       " '/docs/peft',\n",
       " '/docs/datasets',\n",
       " '/docs/text-generation-inference',\n",
       " '/docs/accelerate',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/tasks',\n",
       " 'https://ui.endpoints.huggingface.co',\n",
       " '/chat',\n",
       " '/huggingface',\n",
       " '/brand',\n",
       " '/terms-of-service',\n",
       " '/privacy',\n",
       " 'https://apply.workable.com/huggingface/',\n",
       " 'mailto:press@huggingface.co',\n",
       " '/learn',\n",
       " '/docs',\n",
       " '/blog',\n",
       " 'https://discuss.huggingface.co',\n",
       " 'https://status.huggingface.co/',\n",
       " 'https://github.com/huggingface',\n",
       " 'https://twitter.com/huggingface',\n",
       " 'https://www.linkedin.com/company/huggingface/',\n",
       " '/join/discord']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = Website(\"https://huggingface.co\")\n",
    "page.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aab6d3ff-45a3-487c-b582-0827e0395e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in \\\n",
    "a brochure about the company, such as links to an About page, or a Company page, \\\n",
    "or Careers/Jobs pages. \"\n",
    "link_system_prompt += \"You should respond only in JSON, without text, object as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73a3d491-62b3-4b08-a05e-8029bdb15f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are provided with a list of links found on a webpage. You are able to decide which of the links would be most relevant to include in a brochure about the company, such as links to an About page, or a Company page, or Careers/Jobs pages. You should respond only in JSON, without text, object as in this example:\n",
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
      "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fc24dcb-38a9-4292-9494-63aaa1a4009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for \\\n",
    "    a brochure about the company, respond with the full https URL in clean JSON format \\\n",
    "    without text json on the beginning of the response. \\\n",
    "    Do not include Terms of Service, Privacy, email links. \\n\"\n",
    "    user_prompt += \"Links (some might be relative links): \\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a7c7992-1aa3-48fc-bd07-a3ecbffa8b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of links on the website of https://huggingface.co - please decide which of these are relevant web links for     a brochure about the company, respond with the full https URL in clean JSON format     without text json on the beginning of the response.     Do not include Terms of Service, Privacy, email links. \n",
      "Links (some might be relative links): \n",
      "/\n",
      "/models\n",
      "/datasets\n",
      "/spaces\n",
      "/posts\n",
      "/docs\n",
      "/enterprise\n",
      "/pricing\n",
      "/login\n",
      "/join\n",
      "/spaces\n",
      "/models\n",
      "/nvidia/parakeet-tdt-0.6b-v2\n",
      "/ACE-Step/ACE-Step-v1-3.5B\n",
      "/Lightricks/LTX-Video\n",
      "/nari-labs/Dia-1.6B\n",
      "/lodestones/Chroma\n",
      "/models\n",
      "/spaces/smolagents/computer-agent\n",
      "/spaces/enzostvs/deepsite\n",
      "/spaces/ByteDance/DreamO\n",
      "/spaces/ACE-Step/ACE-Step\n",
      "/spaces/NihalGazi/FLUX-Pro-Unlimited\n",
      "/spaces\n",
      "/datasets/DMindAI/DMind_Benchmark\n",
      "/datasets/nvidia/OpenCodeReasoning\n",
      "/datasets/nvidia/OpenMathReasoning\n",
      "/datasets/nvidia/Nemotron-CrossThink\n",
      "/datasets/openbmb/Ultra-FineWeb\n",
      "/datasets\n",
      "/join\n",
      "/pricing#endpoints\n",
      "/pricing#spaces\n",
      "/pricing\n",
      "/enterprise\n",
      "/enterprise\n",
      "/enterprise\n",
      "/enterprise\n",
      "/enterprise\n",
      "/enterprise\n",
      "/enterprise\n",
      "/allenai\n",
      "/facebook\n",
      "/amazon\n",
      "/google\n",
      "/Intel\n",
      "/microsoft\n",
      "/grammarly\n",
      "/Writer\n",
      "/docs/transformers\n",
      "/docs/diffusers\n",
      "/docs/safetensors\n",
      "/docs/huggingface_hub\n",
      "/docs/tokenizers\n",
      "/docs/trl\n",
      "/docs/transformers.js\n",
      "/docs/smolagents\n",
      "/docs/peft\n",
      "/docs/datasets\n",
      "/docs/text-generation-inference\n",
      "/docs/accelerate\n",
      "/models\n",
      "/datasets\n",
      "/spaces\n",
      "/tasks\n",
      "https://ui.endpoints.huggingface.co\n",
      "/chat\n",
      "/huggingface\n",
      "/brand\n",
      "/terms-of-service\n",
      "/privacy\n",
      "https://apply.workable.com/huggingface/\n",
      "mailto:press@huggingface.co\n",
      "/learn\n",
      "/docs\n",
      "/blog\n",
      "https://discuss.huggingface.co\n",
      "https://status.huggingface.co/\n",
      "https://github.com/huggingface\n",
      "https://twitter.com/huggingface\n",
      "https://www.linkedin.com/company/huggingface/\n",
      "/join/discord\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "795a46af-8164-4857-86c7-3b62ea54b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = ollama.chat(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "        ],\n",
    "        options={\"format\": \"json\"}\n",
    "    )\n",
    "    result = response['message']['content']\n",
    "    #result = re.sub(r\"<think>.*?</think>\", \"\", result, flags=re.DOTALL)\n",
    "    #result = result.strip()\n",
    "    print(result)\n",
    "    try:\n",
    "        content_json = json.loads(result)\n",
    "        return content_json\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Odpowiedź nie jest poprawnym JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "168ba087-6256-4e66-8fe6-69cd6e9d2c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/posts',\n",
       " '/docs',\n",
       " '/enterprise',\n",
       " '/pricing',\n",
       " '/login',\n",
       " '/join',\n",
       " '/spaces',\n",
       " '/models',\n",
       " '/nvidia/parakeet-tdt-0.6b-v2',\n",
       " '/ACE-Step/ACE-Step-v1-3.5B',\n",
       " '/Lightricks/LTX-Video',\n",
       " '/nari-labs/Dia-1.6B',\n",
       " '/lodestones/Chroma',\n",
       " '/models',\n",
       " '/spaces/smolagents/computer-agent',\n",
       " '/spaces/enzostvs/deepsite',\n",
       " '/spaces/ByteDance/DreamO',\n",
       " '/spaces/ACE-Step/ACE-Step',\n",
       " '/spaces/NihalGazi/FLUX-Pro-Unlimited',\n",
       " '/spaces',\n",
       " '/datasets/DMindAI/DMind_Benchmark',\n",
       " '/datasets/nvidia/OpenCodeReasoning',\n",
       " '/datasets/nvidia/OpenMathReasoning',\n",
       " '/datasets/nvidia/Nemotron-CrossThink',\n",
       " '/datasets/openbmb/Ultra-FineWeb',\n",
       " '/datasets',\n",
       " '/join',\n",
       " '/pricing#endpoints',\n",
       " '/pricing#spaces',\n",
       " '/pricing',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/allenai',\n",
       " '/facebook',\n",
       " '/amazon',\n",
       " '/google',\n",
       " '/Intel',\n",
       " '/microsoft',\n",
       " '/grammarly',\n",
       " '/Writer',\n",
       " '/docs/transformers',\n",
       " '/docs/diffusers',\n",
       " '/docs/safetensors',\n",
       " '/docs/huggingface_hub',\n",
       " '/docs/tokenizers',\n",
       " '/docs/trl',\n",
       " '/docs/transformers.js',\n",
       " '/docs/smolagents',\n",
       " '/docs/peft',\n",
       " '/docs/datasets',\n",
       " '/docs/text-generation-inference',\n",
       " '/docs/accelerate',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/tasks',\n",
       " 'https://ui.endpoints.huggingface.co',\n",
       " '/chat',\n",
       " '/huggingface',\n",
       " '/brand',\n",
       " '/terms-of-service',\n",
       " '/privacy',\n",
       " 'https://apply.workable.com/huggingface/',\n",
       " 'mailto:press@huggingface.co',\n",
       " '/learn',\n",
       " '/docs',\n",
       " '/blog',\n",
       " 'https://discuss.huggingface.co',\n",
       " 'https://status.huggingface.co/',\n",
       " 'https://github.com/huggingface',\n",
       " 'https://twitter.com/huggingface',\n",
       " 'https://www.linkedin.com/company/huggingface/',\n",
       " '/join/discord']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface = Website(\"https://huggingface.co\")\n",
    "huggingface.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34aa949c-b2e6-486f-943f-c7d70edcfb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"About page\", \"url\": \"https://huggingface.co/\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/allenai\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/amazon\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/facebook\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/google\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/Intel\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/microsoft\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/grammarly\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/Writer\"},\n",
      "        {\"type\": \"About page\", \"url\": \"https://discuss.huggingface.co/\"},\n",
      "        {\"type\": \"Blog page\", \"url\": \"https://blog.huggingface.co/\"},\n",
      "        {\"type\": \"GitHub page\", \"url\": \"https://github.com/huggingface\"},\n",
      "        {\"type\": \"Twitter page\", \"url\": \"https://twitter.com/huggingface\"},\n",
      "        {\"type\": \"LinkedIn page\", \"url\": \"https://www.linkedin.com/company/huggingface/\"},\n",
      "        {\"type\": \"Discord channel\", \"url\": \"https://join.discord.com/huggingface\"}\n",
      "    ]\n",
      "Odpowiedź nie jest poprawnym JSON\n"
     ]
    }
   ],
   "source": [
    "get_links(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b532d6cc-5ce2-44ff-a63a-584362bd8bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    for link in links[\"links\"]:\n",
    "        try:\n",
    "            result += Website(link[\"url\"]).get_contents()\n",
    "        except socket.gaierror as e:\n",
    "            print(f\"DNS resolution failed: {e}\")\n",
    "        except NameResolutionError as e:\n",
    "            print(f\"Name resolution error: {e}\")\n",
    "        except MaxRetryError as e:\n",
    "            print(f\"Max retries exceeded: {e}\")\n",
    "        except ConnectionError as e:\n",
    "            print(f\"Connection error: {e}\")\n",
    "        except MissingSchema as e:\n",
    "            print(f\"Invalid URL schema: {e}\")\n",
    "        except InvalidSchema as e:\n",
    "            print(f\"Omitted unsupported URL (InvalidSchema): {e}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bee81f69-ca4e-4e29-92b1-5ae3e930e630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"About page\", \"url\": \"https://huggingface.co/\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/allenai\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/facebook\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/amazon\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/google\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/Intel\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/microsoft\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/grammarly\"},\n",
      "        {\"type\": \"Company page\", \"url\": \"https://huggingface.co/Writer\"},\n",
      "        {\"type\": \"Documentation\", \"url\": \"https://docs.huggingface.co/\"}\n",
      "    ]}\n",
      "Connection error: HTTPSConnectionPool(host='docs.huggingface.co', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002629F6E2390>: Failed to resolve 'docs.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Landing page:\n",
      "Webpage Title:\n",
      "Hugging Face – The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "nvidia/parakeet-tdt-0.6b-v2\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "109k\n",
      "•\n",
      "794\n",
      "ACE-Step/ACE-Step-v1-3.5B\n",
      "Updated\n",
      "about 23 hours ago\n",
      "•\n",
      "394\n",
      "Lightricks/LTX-Video\n",
      "Updated\n",
      "8 days ago\n",
      "•\n",
      "250k\n",
      "•\n",
      "1.45k\n",
      "nari-labs/Dia-1.6B\n",
      "Updated\n",
      "about 9 hours ago\n",
      "•\n",
      "159k\n",
      "•\n",
      "2.11k\n",
      "lodestones/Chroma\n",
      "Updated\n",
      "about 4 hours ago\n",
      "•\n",
      "476\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "540\n",
      "540\n",
      "Computer Agent\n",
      "🖥\n",
      "Run tasks using an AI-powered computer agent\n",
      "Running\n",
      "6.48k\n",
      "6.48k\n",
      "DeepSite\n",
      "🐳\n",
      "Generate any application with DeepSeek\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "264\n",
      "264\n",
      "DreamO\n",
      "🐨\n",
      "A Unified Framework for Image Customization\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "312\n",
      "312\n",
      "ACE Step\n",
      "😻\n",
      "A Step Towards Music Generation Foundation Model\n",
      "Running\n",
      "314\n",
      "314\n",
      "FLUX Pro Unlimited\n",
      "🔥\n",
      "Use the FLUX-Pro model as much as you want.\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "DMindAI/DMind_Benchmark\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "1.82k\n",
      "•\n",
      "70\n",
      "nvidia/OpenCodeReasoning\n",
      "Updated\n",
      "9 days ago\n",
      "•\n",
      "15.7k\n",
      "•\n",
      "399\n",
      "nvidia/OpenMathReasoning\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "34.2k\n",
      "•\n",
      "219\n",
      "nvidia/Nemotron-CrossThink\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "12.5k\n",
      "•\n",
      "92\n",
      "openbmb/Ultra-FineWeb\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "1.23k\n",
      "•\n",
      "35\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "•\n",
      "757 models\n",
      "•\n",
      "3.25k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "2.12k models\n",
      "•\n",
      "5.92k followers\n",
      "Amazon\n",
      "company\n",
      "•\n",
      "20 models\n",
      "•\n",
      "3.16k followers\n",
      "Google\n",
      "company\n",
      "•\n",
      "991 models\n",
      "•\n",
      "13.1k followers\n",
      "Intel\n",
      "company\n",
      "•\n",
      "221 models\n",
      "•\n",
      "2.53k followers\n",
      "Microsoft\n",
      "company\n",
      "•\n",
      "374 models\n",
      "•\n",
      "12.3k followers\n",
      "Grammarly\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "10 models\n",
      "•\n",
      "160 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "21 models\n",
      "•\n",
      "267 followers\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "144,293\n",
      "State-of-the-art ML for PyTorch, TensorFlow, JAX\n",
      "Diffusers\n",
      "28,962\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Safetensors\n",
      "3,263\n",
      "Safe way to store/distribute neural network weights\n",
      "Hub Python Library\n",
      "2,594\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Tokenizers\n",
      "9,681\n",
      "Fast tokenizers optimized for research & production\n",
      "TRL\n",
      "13,703\n",
      "Train transformers LMs with reinforcement learning\n",
      "Transformers.js\n",
      "13,577\n",
      "State-of-the-art ML running directly in your browser\n",
      "smolagents\n",
      "18,587\n",
      "Smol library to build great agents in Python\n",
      "PEFT\n",
      "18,387\n",
      "Parameter-efficient finetuning for large language models\n",
      "Datasets\n",
      "20,110\n",
      "Access & share datasets for any ML tasks\n",
      "Text Generation Inference\n",
      "10,115\n",
      "Serve language models with TGI optimized toolkit\n",
      "Accelerate\n",
      "8,708\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Tasks\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "Webpage Title:\n",
      "Hugging Face – The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "nvidia/parakeet-tdt-0.6b-v2\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "109k\n",
      "•\n",
      "794\n",
      "ACE-Step/ACE-Step-v1-3.5B\n",
      "Updated\n",
      "about 23 hours ago\n",
      "•\n",
      "394\n",
      "Lightricks/LTX-Video\n",
      "Updated\n",
      "8 days ago\n",
      "•\n",
      "250k\n",
      "•\n",
      "1.45k\n",
      "nari-labs/Dia-1.6B\n",
      "Updated\n",
      "about 9 hours ago\n",
      "•\n",
      "159k\n",
      "•\n",
      "2.11k\n",
      "lodestones/Chroma\n",
      "Updated\n",
      "about 4 hours ago\n",
      "•\n",
      "476\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "540\n",
      "540\n",
      "Computer Agent\n",
      "🖥\n",
      "Run tasks using an AI-powered computer agent\n",
      "Running\n",
      "6.48k\n",
      "6.48k\n",
      "DeepSite\n",
      "🐳\n",
      "Generate any application with DeepSeek\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "264\n",
      "264\n",
      "DreamO\n",
      "🐨\n",
      "A Unified Framework for Image Customization\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "312\n",
      "312\n",
      "ACE Step\n",
      "😻\n",
      "A Step Towards Music Generation Foundation Model\n",
      "Running\n",
      "314\n",
      "314\n",
      "FLUX Pro Unlimited\n",
      "🔥\n",
      "Use the FLUX-Pro model as much as you want.\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "DMindAI/DMind_Benchmark\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "1.82k\n",
      "•\n",
      "70\n",
      "nvidia/OpenCodeReasoning\n",
      "Updated\n",
      "9 days ago\n",
      "•\n",
      "15.7k\n",
      "•\n",
      "399\n",
      "nvidia/OpenMathReasoning\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "34.2k\n",
      "•\n",
      "219\n",
      "nvidia/Nemotron-CrossThink\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "12.5k\n",
      "•\n",
      "92\n",
      "openbmb/Ultra-FineWeb\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "1.23k\n",
      "•\n",
      "35\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "•\n",
      "757 models\n",
      "•\n",
      "3.25k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "2.12k models\n",
      "•\n",
      "5.92k followers\n",
      "Amazon\n",
      "company\n",
      "•\n",
      "20 models\n",
      "•\n",
      "3.16k followers\n",
      "Google\n",
      "company\n",
      "•\n",
      "991 models\n",
      "•\n",
      "13.1k followers\n",
      "Intel\n",
      "company\n",
      "•\n",
      "221 models\n",
      "•\n",
      "2.53k followers\n",
      "Microsoft\n",
      "company\n",
      "•\n",
      "374 models\n",
      "•\n",
      "12.3k followers\n",
      "Grammarly\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "10 models\n",
      "•\n",
      "160 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "21 models\n",
      "•\n",
      "267 followers\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "144,293\n",
      "State-of-the-art ML for PyTorch, TensorFlow, JAX\n",
      "Diffusers\n",
      "28,962\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Safetensors\n",
      "3,263\n",
      "Safe way to store/distribute neural network weights\n",
      "Hub Python Library\n",
      "2,594\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Tokenizers\n",
      "9,681\n",
      "Fast tokenizers optimized for research & production\n",
      "TRL\n",
      "13,703\n",
      "Train transformers LMs with reinforcement learning\n",
      "Transformers.js\n",
      "13,577\n",
      "State-of-the-art ML running directly in your browser\n",
      "smolagents\n",
      "18,587\n",
      "Smol library to build great agents in Python\n",
      "PEFT\n",
      "18,387\n",
      "Parameter-efficient finetuning for large language models\n",
      "Datasets\n",
      "20,110\n",
      "Access & share datasets for any ML tasks\n",
      "Text Generation Inference\n",
      "10,115\n",
      "Serve language models with TGI optimized toolkit\n",
      "Accelerate\n",
      "8,708\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Tasks\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "Webpage Title:\n",
      "allenai (Ai2)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "Verified\n",
      "https://allenai.org/\n",
      "allen_ai\n",
      "allenai\n",
      "Activity Feed\n",
      "Follow\n",
      "3,253\n",
      "AI & ML interests\n",
      "Building breatkthrough AI to solve the world's biggest problems.\n",
      "Recent Activity\n",
      "amanrangapur\n",
      "updated\n",
      "a model\n",
      "less than a minute ago\n",
      "allenai/OLMo-2-0325-32B\n",
      "array\n",
      "authored\n",
      "a paper\n",
      "about 3 hours ago\n",
      "SAT: Spatial Aptitude Training for Multimodal Language Models\n",
      "Muennighoff\n",
      "authored\n",
      "a paper\n",
      "5 days ago\n",
      "Crosslingual Reasoning through Test-Time Scaling\n",
      "View all activity\n",
      "Articles\n",
      "Introducing the Open Chain of Thought Leaderboard\n",
      "Apr 23, 2024\n",
      "•\n",
      "33\n",
      "Team members\n",
      "176\n",
      "+142\n",
      "+129\n",
      "+108\n",
      "+98\n",
      "+78\n",
      "Organization Card\n",
      "Community\n",
      "About org cards\n",
      "Collections\n",
      "20\n",
      "OLMo 2\n",
      "Artifacts for the OLMo 2 release.\n",
      "allenai/OLMo-2-0425-1B-Instruct\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "2.08k\n",
      "•\n",
      "32\n",
      "allenai/OLMo-2-0425-1B-Instruct-GGUF\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "1.17k\n",
      "•\n",
      "6\n",
      "allenai/OLMo-2-0425-1B\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "14 days ago\n",
      "•\n",
      "7.31k\n",
      "•\n",
      "42\n",
      "allenai/OLMo-2-0325-32B-Instruct\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Mar 14\n",
      "•\n",
      "8.39k\n",
      "•\n",
      "132\n",
      "olmOCR\n",
      "olmOCR is a document recognition pipeline for efficiently converting documents into plain text. \n",
      "\n",
      "olmocr.allenai.org\n",
      "allenai/olmOCR-7B-0225-preview\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "Feb 25\n",
      "•\n",
      "367k\n",
      "•\n",
      "640\n",
      "allenai/olmOCR-mix-0225\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Feb 25\n",
      "•\n",
      "259k\n",
      "•\n",
      "1.8k\n",
      "•\n",
      "127\n",
      "allenai/olmOCR-7B-0225-preview-GGUF\n",
      "Updated\n",
      "Feb 26\n",
      "•\n",
      "1.12k\n",
      "•\n",
      "27\n",
      "Expand 20 collections\n",
      "spaces\n",
      "10\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "pinned\n",
      "Running\n",
      "87\n",
      "Zebra Logic Bench\n",
      "🦓\n",
      "Render a leaderboard for model evaluation\n",
      "allenai\n",
      "Apr 2\n",
      "pinned\n",
      "Running\n",
      "1\n",
      "SUPER Leaderboard\n",
      "🤖\n",
      "allenai\n",
      "Feb 10\n",
      "pinned\n",
      "Runtime error\n",
      "2\n",
      "HREF Leaderboard\n",
      "📐\n",
      "allenai\n",
      "Dec 23, 2024\n",
      "pinned\n",
      "Running\n",
      "364\n",
      "Reward Bench Leaderboard\n",
      "📐\n",
      "Explore and analyze RewardBench leaderboard data\n",
      "allenai\n",
      "Dec 11, 2024\n",
      "pinned\n",
      "Running\n",
      "50\n",
      "ZeroEval Leaderboard\n",
      "📊\n",
      "Embed and use ZeroEval for evaluation tasks\n",
      "allenai\n",
      "Nov 22, 2024\n",
      "pinned\n",
      "Running\n",
      "22\n",
      "BaseChat by URIAL (Chat with base, untuned LLMs)\n",
      "💬\n",
      "Chat with advanced language models\n",
      "allenai\n",
      "Aug 6, 2024\n",
      "Expand\n",
      "\t\t\t\t\t\t\t10\n",
      "\t\t\t\t\t\t\t\tspaces\n",
      "models\n",
      "757\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "allenai/ACE2-EAMv3\n",
      "Updated\n",
      "1 day ago\n",
      "allenai/OLMo-2-0425-1B-Instruct-GGUF\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "1.17k\n",
      "•\n",
      "6\n",
      "allenai/OLMo-2-0425-1B-SFT\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "209\n",
      "•\n",
      "1\n",
      "allenai/OLMo-2-0425-1B-DPO\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "157\n",
      "•\n",
      "2\n",
      "allenai/OLMo-2-0425-1B-RLVR1\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "72\n",
      "allenai/OLMo-2-0425-1B-Instruct\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "2.08k\n",
      "•\n",
      "32\n",
      "allenai/OLMo-2-0425-1B\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "14 days ago\n",
      "•\n",
      "7.31k\n",
      "•\n",
      "42\n",
      "allenai/OLMo-2-0425-1B-GGUF\n",
      "Updated\n",
      "14 days ago\n",
      "•\n",
      "349\n",
      "allenai/OLMo-2-0325-32B-Instruct-GGUF\n",
      "Updated\n",
      "14 days ago\n",
      "•\n",
      "554\n",
      "•\n",
      "15\n",
      "allenai/OLMo-Ladder-760M-0.5xC\n",
      "Updated\n",
      "14 days ago\n",
      "•\n",
      "288\n",
      "Expand\n",
      "\t\t\t\t\t\t\t757\n",
      "\t\t\t\t\t\t\t\tmodels\n",
      "datasets\n",
      "224\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "allenai/discoverybench\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "264\n",
      "•\n",
      "223\n",
      "•\n",
      "12\n",
      "allenai/reward-bench-results\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "3.05k\n",
      "•\n",
      "2\n",
      "allenai/DataDecide-data-recipes\n",
      "Updated\n",
      "8 days ago\n",
      "•\n",
      "13.3k\n",
      "•\n",
      "7\n",
      "allenai/olmo-2-0425-1b-preference-mix\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "14 days ago\n",
      "•\n",
      "378k\n",
      "•\n",
      "164\n",
      "•\n",
      "2\n",
      "allenai/DataDecide-eval-results\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "28 days ago\n",
      "•\n",
      "1.41M\n",
      "•\n",
      "251\n",
      "•\n",
      "4\n",
      "allenai/sqa_reranking_eval\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "29 days ago\n",
      "•\n",
      "2.43k\n",
      "•\n",
      "197\n",
      "•\n",
      "1\n",
      "allenai/tulu-3-do-anything-now-eval\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Apr 11\n",
      "•\n",
      "300\n",
      "•\n",
      "68\n",
      "allenai/tulu-3-harmbench-eval\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Apr 11\n",
      "•\n",
      "320\n",
      "•\n",
      "62\n",
      "allenai/tulu-3-trustllm-jailbreaktrigger-eval\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Apr 11\n",
      "•\n",
      "400\n",
      "•\n",
      "54\n",
      "allenai/big-reasoning-traces\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Apr 1\n",
      "•\n",
      "677k\n",
      "•\n",
      "485\n",
      "•\n",
      "3\n",
      "Expand\n",
      "\t\t\t\t\t\t\t224\n",
      "\t\t\t\t\t\t\t\tdatasets\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "Webpage Title:\n",
      "facebook (AI at Meta)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "Verified\n",
      "https://ai.facebook.com/\n",
      "facebookresearch\n",
      "Activity Feed\n",
      "Follow\n",
      "5,921\n",
      "AI & ML interests\n",
      "None defined yet.\n",
      "Recent Activity\n",
      "ybenchetrit\n",
      "published\n",
      "a model\n",
      "about 1 hour ago\n",
      "facebook/dynadiff\n",
      "dieuwkehupkes\n",
      "updated\n",
      "a dataset\n",
      "about 1 hour ago\n",
      "facebook/multiloko\n",
      "bkmi\n",
      "updated\n",
      "a model\n",
      "about 5 hours ago\n",
      "facebook/adjoint_sampling\n",
      "View all activity\n",
      "Articles\n",
      "Faster Text Generation with Self-Speculative Decoding\n",
      "Nov 20, 2024\n",
      "•\n",
      "58\n",
      "Team members\n",
      "274\n",
      "+240\n",
      "+227\n",
      "+206\n",
      "+196\n",
      "+176\n",
      "Collections\n",
      "29\n",
      "Web-SSL\n",
      "facebook/webssl-dino300m-full2b-224\n",
      "Image Feature Extraction\n",
      "•\n",
      "Updated\n",
      "20 days ago\n",
      "•\n",
      "2.55k\n",
      "•\n",
      "8\n",
      "facebook/webssl-dino1b-full2b-224\n",
      "Image Feature Extraction\n",
      "•\n",
      "Updated\n",
      "20 days ago\n",
      "•\n",
      "8.23k\n",
      "•\n",
      "1\n",
      "facebook/webssl-dino2b-full2b-224\n",
      "Image Feature Extraction\n",
      "•\n",
      "Updated\n",
      "20 days ago\n",
      "•\n",
      "75\n",
      "facebook/webssl-dino3b-full2b-224\n",
      "Image Feature Extraction\n",
      "•\n",
      "Updated\n",
      "20 days ago\n",
      "•\n",
      "130\n",
      "blt\n",
      "facebook/blt\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "5\n",
      "•\n",
      "54\n",
      "facebook/blt-1b\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "296\n",
      "•\n",
      "15\n",
      "facebook/blt-7b\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "46\n",
      "•\n",
      "59\n",
      "Byte Latent Transformer: Patches Scale Better Than Tokens\n",
      "Paper\n",
      "•\n",
      "2412.09871\n",
      "•\n",
      "Published\n",
      "Dec 13, 2024\n",
      "•\n",
      "103\n",
      "Expand 29 collections\n",
      "spaces\n",
      "36\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "pinned\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "91\n",
      "MelodyFlow\n",
      "🎵\n",
      "Generate music from text and melody\n",
      "facebook\n",
      "Jan 4\n",
      "pinned\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "264\n",
      "CoTracker\n",
      "🎨\n",
      "Track points in a video\n",
      "facebook\n",
      "Oct 17, 2024\n",
      "pinned\n",
      "Running\n",
      "on\n",
      "A10G\n",
      "4.94k\n",
      "MusicGen\n",
      "🎵\n",
      "Generate music from text descriptions\n",
      "facebook\n",
      "Dec 20, 2023\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "15\n",
      "EdgeTAM\n",
      "🚀\n",
      "On-Device Track Anything Model\n",
      "facebook\n",
      "8 days ago\n",
      "Running\n",
      "9\n",
      "Bouquet\n",
      "🔥\n",
      "Universal Quality Evaluation in Translation\n",
      "facebook\n",
      "21 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "169\n",
      "vggt\n",
      "🏆\n",
      "VGGT (CVPR 2025)\n",
      "facebook\n",
      "Mar 17\n",
      "Expand\n",
      "\t\t\t\t\t\t\t36\n",
      "\t\t\t\t\t\t\t\tspaces\n",
      "models\n",
      "2,124\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "facebook/adjoint_sampling\n",
      "Updated\n",
      "about 5 hours ago\n",
      "•\n",
      "3\n",
      "facebook/UMA\n",
      "Updated\n",
      "about 6 hours ago\n",
      "•\n",
      "3\n",
      "facebook/OMol25\n",
      "Updated\n",
      "about 6 hours ago\n",
      "•\n",
      "3\n",
      "facebook/VGGSfM\n",
      "Image-to-3D\n",
      "•\n",
      "Updated\n",
      "about 6 hours ago\n",
      "•\n",
      "8\n",
      "facebook/dynadiff\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "2\n",
      "facebook/VGGT_tracker_fixed\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "2\n",
      "facebook/MobileLLM-350M-layer-share\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "9 days ago\n",
      "•\n",
      "247\n",
      "•\n",
      "6\n",
      "facebook/MobileLLM-125M-layer-share\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "9 days ago\n",
      "•\n",
      "317\n",
      "•\n",
      "7\n",
      "facebook/MobileLLM-1.5B\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "9 days ago\n",
      "•\n",
      "112\n",
      "•\n",
      "9\n",
      "facebook/MobileLLM-1B\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "9 days ago\n",
      "•\n",
      "1.89k\n",
      "•\n",
      "121\n",
      "Expand\n",
      "\t\t\t\t\t\t\t2,124\n",
      "\t\t\t\t\t\t\t\tmodels\n",
      "datasets\n",
      "65\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "facebook/multiloko\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "about 1 hour ago\n",
      "•\n",
      "37.8k\n",
      "•\n",
      "1\n",
      "facebook/Wildchat-RIP-Filtered-by-8b-Llama\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "about 17 hours ago\n",
      "•\n",
      "24.3k\n",
      "•\n",
      "79\n",
      "•\n",
      "2\n",
      "facebook/llamafirewall-alignmentcheck-evals\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "15 days ago\n",
      "•\n",
      "3.46k\n",
      "•\n",
      "82\n",
      "facebook/PLM-VideoBench\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "21 days ago\n",
      "•\n",
      "44k\n",
      "•\n",
      "1.99k\n",
      "•\n",
      "9\n",
      "facebook/PLM-Image-Auto\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "23 days ago\n",
      "•\n",
      "30.3M\n",
      "•\n",
      "904\n",
      "•\n",
      "12\n",
      "facebook/PLM-Video-Auto\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "23 days ago\n",
      "•\n",
      "6.41M\n",
      "•\n",
      "585\n",
      "•\n",
      "12\n",
      "facebook/PE-Video\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "25 days ago\n",
      "•\n",
      "118k\n",
      "•\n",
      "11.4k\n",
      "•\n",
      "26\n",
      "facebook/PLM-Video-Human\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "26 days ago\n",
      "•\n",
      "2.8M\n",
      "•\n",
      "2.89k\n",
      "•\n",
      "21\n",
      "facebook/BigOBench\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Mar 20\n",
      "•\n",
      "1.19M\n",
      "•\n",
      "1.38k\n",
      "•\n",
      "2\n",
      "facebook/collaborative_agent_bench\n",
      "Preview\n",
      "•\n",
      "Updated\n",
      "Mar 20\n",
      "•\n",
      "148\n",
      "•\n",
      "57\n",
      "Expand\n",
      "\t\t\t\t\t\t\t65\n",
      "\t\t\t\t\t\t\t\tdatasets\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "Webpage Title:\n",
      "amazon (Amazon)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Amazon\n",
      "company\n",
      "Verified\n",
      "https://aws.amazon.com/\n",
      "aws\n",
      "Activity Feed\n",
      "Request to join this org\n",
      "Follow\n",
      "3,155\n",
      "AI & ML interests\n",
      "Scalable Artificial Intelligence\n",
      "Recent Activity\n",
      "LahariChowtoori\n",
      "updated\n",
      "a Space\n",
      "about 1 month ago\n",
      "amazon/README\n",
      "danteev\n",
      "new\n",
      "activity\n",
      "2 months ago\n",
      "amazon/AmazonQAC:\n",
      "Parquet file and dataset info/Croissant have different columns\n",
      "lostella\n",
      "new\n",
      "activity\n",
      "2 months ago\n",
      "amazon/chronos-t5-mini:\n",
      "[ERROR] Chronos Inference on GPU with Torch\n",
      "View all activity\n",
      "Team members\n",
      "2374\n",
      "+2340\n",
      "+2327\n",
      "+2306\n",
      "+2296\n",
      "+2276\n",
      "Organization Card\n",
      "Community\n",
      "About org cards\n",
      "Innovating with machine learning on AWS\n",
      "On AWS, you can access performant infrastructure, deployment resources, data governance solutions, and deep learning containers (DLCs) with optimized open source frameworks, so that you can focus on your machine learning tasks.\n",
      "Build and Scale AI/ML on AWS\n",
      "AWS offers a comprehensive suite of AI/ML tools and services that cater to every stage of the machine learning lifecycle. From model development and training to deployment and inference, AWS provides cutting-edge solutions such as Amazon SageMaker AI, a fully-managed service for end-to-end development and deployment of models, Amazon Bedrock for building and scaling generative AI applications with foundation models, custom AI accelerator chips such as AWS Trainium for training and AWS Inferentia for inference, and pre-configured environments to streamline your ML workflows. Additionally, you can explore the Registry of Open Data to discover, access, and utilize diverse datasets for your AI/ML projects. Whether you're working on large language models, generative AI, computer vision, time-series forecasting, or natural language processing, scaling your projects on AWS is easy.\n",
      "Learn more about these services and others:\n",
      "Amazon SageMaker AI\n",
      "Amazon Bedrock\n",
      "AWS AI Chips\n",
      "AWS GPUs for Machine Learning\n",
      "AWS Deep Learning AMIs\n",
      "AWS Deep Learning Containers (DLCs)\n",
      "Artificial Intelligence on AWS\n",
      "Registry of Open Data\n",
      "AWS & Hugging Face Collaboration\n",
      "AWS and Hugging Face are working together to simplify and accelerate the adoption of advanced machine learning models. This\n",
      "collaboration\n",
      "offers streamlined training using Hugging Face Deep Learning Containers with SageMaker AI distributed training libraries, simplifying workflows with the SageMaker AI Python SDK for efficient model training. Deployment is made effortless through the Hugging Face Inference toolkit and DLCs, allowing users to deploy trained models on the Hugging Face Hub. Amazon SageMaker AI facilitates the creation of scalable endpoints with built-in monitoring and enterprise-level security. This joint effort empowers teams to move quickly from experimentation to production, leveraging cutting-edge models and scalable infrastructure to drive innovation in machine learning projects.\n",
      "Learn about\n",
      "Hugging Face on AWS\n",
      "Learn about\n",
      "Hugging Face on Amazon SageMaker AI\n",
      "Reference documentation for\n",
      "using Hugging Face with Amazon SageMaker AI\n",
      "Community Forum\n",
      "on Hugging Face\n",
      "Connect, Learn, and Grow with AWS\n",
      "Stay connected with the latest AWS AI/ML and open source developments:\n",
      "AWS Open Source\n",
      "AWS on GitHub\n",
      "AWS on LinkedIn\n",
      "Open Source At AWS\n",
      "Amazon Science\n",
      "Amazon Science on GitHub\n",
      "Amazon Science on LinkedIn\n",
      "Code and Datasets from Amazon Researchers\n",
      "AWS Community\n",
      "AWS Machine Learning Blog\n",
      "AWS Community Posts about Hugging Face\n",
      "AWS Community Posts about AI/ML\n",
      "AWS Developers\n",
      "Generative AI on AWS\n",
      "Data and Machine Learning on AWS\n",
      "ML Specialist Training & Resources\n",
      "Check out these other Amazon-run Hugging Face organizations\n",
      "AutoGluon\n",
      "AWS Inferentia and Trainium\n",
      "Amazon Science\n",
      "Let's innovate together! 🎉🚀\n",
      "LLM experimentation at scale using Amazon SageMaker Pipelines and MLflow\n",
      "Build a Hugging Face text classification model in Amazon SageMaker JumpStart\n",
      "Inference AudioCraft MusicGen models using Amazon SageMaker\n",
      "Collections\n",
      "2\n",
      "Chronos-Bolt⚡️ Models\n",
      "Chronos-Bolt pretrained models for time series forecasting.\n",
      "amazon/chronos-bolt-tiny\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "346k\n",
      "•\n",
      "20\n",
      "amazon/chronos-bolt-mini\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "791k\n",
      "•\n",
      "5\n",
      "amazon/chronos-bolt-small\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "534k\n",
      "•\n",
      "10\n",
      "amazon/chronos-bolt-base\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "994k\n",
      "•\n",
      "45\n",
      "Chronos Models & Datasets\n",
      "Collection of artifacts related to Chronos pretrained models for time series forecasting.\n",
      "amazon/chronos-bolt-tiny\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "346k\n",
      "•\n",
      "20\n",
      "amazon/chronos-bolt-mini\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "791k\n",
      "•\n",
      "5\n",
      "amazon/chronos-bolt-small\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "534k\n",
      "•\n",
      "10\n",
      "amazon/chronos-bolt-base\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "994k\n",
      "•\n",
      "45\n",
      "models\n",
      "20\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "amazon/chronos-bolt-tiny\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "346k\n",
      "•\n",
      "20\n",
      "amazon/chronos-bolt-mini\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "791k\n",
      "•\n",
      "5\n",
      "amazon/chronos-bolt-small\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "534k\n",
      "•\n",
      "10\n",
      "amazon/chronos-bolt-base\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "994k\n",
      "•\n",
      "45\n",
      "amazon/chronos-t5-large\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "116k\n",
      "•\n",
      "141\n",
      "amazon/chronos-t5-base\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "2.1M\n",
      "•\n",
      "31\n",
      "amazon/chronos-t5-small\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "38.9M\n",
      "•\n",
      "71\n",
      "amazon/chronos-t5-mini\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "120k\n",
      "•\n",
      "16\n",
      "amazon/chronos-t5-tiny\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "458k\n",
      "•\n",
      "106\n",
      "amazon/MistralLite-AWQ\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "May 20, 2024\n",
      "•\n",
      "51\n",
      "•\n",
      "3\n",
      "Expand\n",
      "\t\t\t\t\t\t\t20\n",
      "\t\t\t\t\t\t\t\tmodels\n",
      "datasets\n",
      "2\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "amazon/CodePrefBench\n",
      "Preview\n",
      "•\n",
      "Updated\n",
      "Nov 25, 2024\n",
      "•\n",
      "26\n",
      "•\n",
      "1\n",
      "amazon/AmazonQAC\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Nov 19, 2024\n",
      "•\n",
      "396M\n",
      "•\n",
      "281\n",
      "•\n",
      "14\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "Webpage Title:\n",
      "google (Google)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Google\n",
      "company\n",
      "Verified\n",
      "Activity Feed\n",
      "Follow\n",
      "13,116\n",
      "AI & ML interests\n",
      "Google ❤️ Open Source AI\n",
      "Recent Activity\n",
      "PhilCulliton\n",
      "authored\n",
      "a paper\n",
      "about 3 hours ago\n",
      "Position: AI Competitions Provide the Gold Standard for Empirical Rigor\n",
      "  in GenAI Evaluation\n",
      "lkv\n",
      "new\n",
      "activity\n",
      "about 3 hours ago\n",
      "google/gemma-3-1b-it:\n",
      "AttributeError: 'HybridCache' object has no attribute 'float'\n",
      "lkv\n",
      "new\n",
      "activity\n",
      "about 3 hours ago\n",
      "google/gemma-3-4b-it:\n",
      "AttributeError: 'HybridCache' object has no attribute 'float'\n",
      "View all activity\n",
      "Articles\n",
      "PaliGemma 2 Mix - New Instruction Vision Language Models by Google\n",
      "Feb 19\n",
      "•\n",
      "70\n",
      "Welcome PaliGemma 2 – New vision language models by Google\n",
      "Dec 5, 2024\n",
      "•\n",
      "153\n",
      "PaliGemma – Google's Cutting-Edge Open Vision Language Model\n",
      "May 14, 2024\n",
      "•\n",
      "250\n",
      "Team members\n",
      "2343\n",
      "+2309\n",
      "+2296\n",
      "+2275\n",
      "+2265\n",
      "+2245\n",
      "Organization Card\n",
      "Community\n",
      "About org cards\n",
      "Welcome to the official Google organization on Hugging Face!\n",
      "Google collaborates with Hugging Face\n",
      "across open science, open source, cloud, and hardware to\n",
      "enable companies to innovate with AI\n",
      "on Google Cloud AI services and infrastructure with the Hugging Face ecosystem\n",
      ".\n",
      "Featured Models and Tools\n",
      "Gemma Family of Open Multimodal Models\n",
      "Gemma\n",
      "is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models\n",
      "PaliGemma\n",
      "is a versatile and lightweight vision-language model (VLM)\n",
      "CodeGemma\n",
      "is a collection of lightweight open code models built on top of Gemma\n",
      "RecurrentGemma\n",
      "is a family of open language models built on a novel recurrent architecture developed at Google\n",
      "ShieldGemma\n",
      "is a series of safety content moderation models built upon Gemma 2 that target four harm categories\n",
      "Health AI Developer Foundations\n",
      "TxGemma\n",
      "collection of open models to accelerate the development of therapeutics\n",
      "CXR Foundation\n",
      "embedding model for efficiently building AI for chest X-ray applications\n",
      "Path Foundation\n",
      "embedding model for efficiently building AI for histopathology applications\n",
      "Derm Foundation\n",
      "embedding model for efficiently building AI for skin imaging applications\n",
      "HeAR\n",
      "(\n",
      "TensorFlow\n",
      ",\n",
      "PyTorch\n",
      ") embedding model for efficiently building AI related to audio originating from the respiratory system\n",
      "BERT\n",
      ",\n",
      "T5\n",
      ", and\n",
      "TimesFM\n",
      "Model Families\n",
      "Author ML models with\n",
      "MaxText\n",
      ",\n",
      "JAX\n",
      ",\n",
      "Keras\n",
      ",\n",
      "Tensorflow\n",
      ", and\n",
      "PyTorch/XLA\n",
      "SynthID\n",
      "is a Google DeepMind technology that watermarks and identifies AI-generated content (\n",
      "🤗 Space\n",
      ")\n",
      "Open Research and Community Resources\n",
      "Google Blogs\n",
      ":\n",
      "https://blog.google/\n",
      "https://cloud.google.com/blog/\n",
      "https://deepmind.google/discover/blog/\n",
      "https://developers.google.com/learn?category=aiandmachinelearning\n",
      "https://research.google/blog/\n",
      "Notable GitHub Repositories\n",
      ":\n",
      "https://github.com/google/jax\n",
      "is a Python library for high-performance numerical computing and machine learning\n",
      "https://github.com/huggingface/Google-Cloud-Containers\n",
      "facilitate the training and deployment of Hugging Face models on Google Cloud\n",
      "https://github.com/pytorch/xla\n",
      "enables PyTorch on XLA Devices (e.g. Google TPU)\n",
      "https://github.com/huggingface/optimum-tpu\n",
      "brings the power of TPUs to your training and inference stack\n",
      "https://github.com/openxla/xla\n",
      "is a machine learning compiler for GPUs, CPUs, and ML accelerators\n",
      "https://github.com/google/JetStream\n",
      "(and\n",
      "https://github.com/google/jetstream-pytorch\n",
      ") is a throughput and memory optimized engine for large language model (LLM) inference on XLA devices\n",
      "https://github.com/google/flax\n",
      "is a neural network library for JAX that is designed for flexibility\n",
      "https://github.com/kubernetes-sigs/lws\n",
      "facilitates Kubernetes deployment patterns for AI/ML inference workloads, especially multi-host inference workloads\n",
      "https://github.com/GoogleCloudPlatform/ai-on-gke\n",
      "is a collection of AI examples, best-practices, and prebuilt solutions\n",
      "Google Research Papers\n",
      ":\n",
      "https://research.google/\n",
      "On-device ML using\n",
      "Google AI Edge\n",
      "Customize and run common ML Tasks with low-code\n",
      "MediaPipe Solutions\n",
      "Run\n",
      "pretrained\n",
      "or custom models on-device with\n",
      "Lite RT (previously known as TensorFlow Lite)\n",
      "Convert\n",
      "TensorFlow\n",
      "and\n",
      "JAX\n",
      "models to LiteRT\n",
      "Convert PyTorch models to LiteRT and author high performance on-device LLMs with\n",
      "AI Edge Torch\n",
      "Visualize and debug models with\n",
      "Model Explorer\n",
      "(\n",
      "🤗 Space\n",
      ")\n",
      "Partnership Highlights and Resources\n",
      "Select Google Cloud CPU, GPU, or TPU options when setting up your\n",
      "Hugging Face\n",
      "Inference Endpoints\n",
      "and Spaces\n",
      "Train and Deploy Hugging Face models\n",
      "on Google Kubernetes Engine (GKE) and Vertex AI\n",
      "directly from Hugging Face model landing pages or from Google Cloud Model Garden\n",
      "Integrate\n",
      "Colab\n",
      "notebooks with Hugging Face Hub\n",
      "via the\n",
      "HF_TOKEN secret manager integration\n",
      "and transformers/huggingface_hub pre-installs\n",
      "Leverage\n",
      "Hugging Face Deep Learning Containers (DLCs)\n",
      "for easy training and deployment of Hugging Face models on Google Cloud infrastructure\n",
      "Run optimized, zero-configuration inference microservices with\n",
      "Hugging Face Generative AI Services (HUGS) via the Google Cloud Marketplace\n",
      "Read about our principles for responsible AI at\n",
      "https://ai.google/responsibility/principles\n",
      "Collections\n",
      "35\n",
      "Gemma 3 Release\n",
      "google/gemma-3-4b-it\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "Mar 21\n",
      "•\n",
      "601k\n",
      "•\n",
      "518\n",
      "google/gemma-3-4b-pt\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "Mar 21\n",
      "•\n",
      "50.7k\n",
      "•\n",
      "70\n",
      "google/gemma-3-1b-pt\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Mar 21\n",
      "•\n",
      "150k\n",
      "•\n",
      "114\n",
      "google/gemma-3-1b-it\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 4\n",
      "•\n",
      "2.86M\n",
      "•\n",
      "387\n",
      "Gemma 3 QAT\n",
      "Quantization Aware Trained (QAT) Gemma 3 checkpoints. The model preserves similar quality as half precision while using 3x less memory\n",
      "google/gemma-3-4b-it-qat-q4_0-gguf\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "Apr 11\n",
      "•\n",
      "15.5k\n",
      "•\n",
      "137\n",
      "google/gemma-3-4b-pt-qat-q4_0-gguf\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "Apr 3\n",
      "•\n",
      "806\n",
      "•\n",
      "18\n",
      "google/gemma-3-1b-it-qat-q4_0-gguf\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 11\n",
      "•\n",
      "3.66k\n",
      "•\n",
      "39\n",
      "google/gemma-3-1b-pt-qat-q4_0-gguf\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 3\n",
      "•\n",
      "250\n",
      "•\n",
      "6\n",
      "Expand 35 collections\n",
      "spaces\n",
      "8\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "Running\n",
      "8\n",
      "Path Foundation Demo\n",
      "🔬\n",
      "Access pathology images for medical reference\n",
      "google\n",
      "Apr 1\n",
      "Running\n",
      "5\n",
      "CXR Foundation Demo\n",
      "🩻\n",
      "Demo usage of the CXR Foundation model embeddings\n",
      "google\n",
      "Mar 28\n",
      "Running\n",
      "43\n",
      "Compare Siglip1 Siglip2\n",
      "🚀\n",
      "Compare SigLIP1 and SigLIP2 on zero shot classification\n",
      "google\n",
      "Feb 20\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "89\n",
      "Paligemma2 Mix\n",
      "🌖\n",
      "Generate text or segment objects from an image\n",
      "google\n",
      "Feb 19\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "1.97k\n",
      "Stable Diffusion XL on TPUv5e\n",
      "🏋\n",
      "Generate images from text prompts with various styles\n",
      "google\n",
      "Jan 28\n",
      "Running\n",
      "on\n",
      "L40S\n",
      "49\n",
      "SynthID Text\n",
      "🏃\n",
      "Watermarking LLM-generated text with SynthID Text\n",
      "google\n",
      "Nov 1, 2024\n",
      "Expand\n",
      "\t\t\t\t\t\t\t8\n",
      "\t\t\t\t\t\t\t\tspaces\n",
      "models\n",
      "991\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "google/hear-pytorch\n",
      "Image Feature Extraction\n",
      "•\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "64\n",
      "•\n",
      "9\n",
      "google/tapnet\n",
      "Updated\n",
      "8 days ago\n",
      "•\n",
      "6\n",
      "google/hear\n",
      "Updated\n",
      "27 days ago\n",
      "•\n",
      "113\n",
      "•\n",
      "18\n",
      "google/timesfm-2.0-500m-pytorch\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "28 days ago\n",
      "•\n",
      "159\n",
      "google/gemma-3-12b-it-qat-int4-unquantized\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "29 days ago\n",
      "•\n",
      "1.98k\n",
      "•\n",
      "8\n",
      "google/gemma-3-4b-it-qat-int4-unquantized\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "29 days ago\n",
      "•\n",
      "1.05k\n",
      "•\n",
      "2\n",
      "google/gemma-3-1b-it-qat-int4-unquantized\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "29 days ago\n",
      "•\n",
      "1.53k\n",
      "•\n",
      "3\n",
      "google/gemma-3-27b-it-qat-q4_0-unquantized\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "29 days ago\n",
      "•\n",
      "36.4k\n",
      "•\n",
      "27\n",
      "google/gemma-3-12b-it-qat-q4_0-unquantized\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "29 days ago\n",
      "•\n",
      "2.02k\n",
      "•\n",
      "9\n",
      "google/gemma-3-1b-it-qat-q4_0-unquantized\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "29 days ago\n",
      "•\n",
      "1.04k\n",
      "•\n",
      "4\n",
      "Expand\n",
      "\t\t\t\t\t\t\t991\n",
      "\t\t\t\t\t\t\t\tmodels\n",
      "datasets\n",
      "53\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "google/wmt24pp\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Mar 13\n",
      "•\n",
      "54.9k\n",
      "•\n",
      "2.66k\n",
      "•\n",
      "40\n",
      "google/smol\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Mar 3\n",
      "•\n",
      "811k\n",
      "•\n",
      "1.15k\n",
      "•\n",
      "52\n",
      "google/wmt24pp-images\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Feb 24\n",
      "•\n",
      "170\n",
      "•\n",
      "81\n",
      "•\n",
      "4\n",
      "google/spiqa\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jan 8\n",
      "•\n",
      "666\n",
      "•\n",
      "427\n",
      "•\n",
      "37\n",
      "google/FACTS-grounding-public\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Dec 19, 2024\n",
      "•\n",
      "868\n",
      "•\n",
      "303\n",
      "•\n",
      "28\n",
      "google/frames-benchmark\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Oct 15, 2024\n",
      "•\n",
      "824\n",
      "•\n",
      "1.38k\n",
      "•\n",
      "200\n",
      "google/flame-collection\n",
      "Updated\n",
      "Sep 23, 2024\n",
      "•\n",
      "15\n",
      "•\n",
      "1\n",
      "google/xtreme_s\n",
      "Updated\n",
      "Sep 10, 2024\n",
      "•\n",
      "6.73k\n",
      "•\n",
      "62\n",
      "google/coverbench\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Sep 5, 2024\n",
      "•\n",
      "733\n",
      "•\n",
      "33\n",
      "•\n",
      "10\n",
      "google/quickdraw\n",
      "Updated\n",
      "Aug 27, 2024\n",
      "•\n",
      "331\n",
      "•\n",
      "21\n",
      "Expand\n",
      "\t\t\t\t\t\t\t53\n",
      "\t\t\t\t\t\t\t\tdatasets\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "Webpage Title:\n",
      "Intel (Intel)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Intel\n",
      "company\n",
      "Verified\n",
      "Activity Feed\n",
      "Request to join this org\n",
      "Follow\n",
      "2,533\n",
      "AI & ML interests\n",
      "None defined yet.\n",
      "Recent Activity\n",
      "wenhuach\n",
      "updated\n",
      "a model\n",
      "1 day ago\n",
      "Intel/Qwen2-0.5B-Instruct-int4-sym-AutoRound\n",
      "wenhuach\n",
      "published\n",
      "a model\n",
      "1 day ago\n",
      "Intel/Qwen2-0.5B-Instruct-int4-sym-AutoRound\n",
      "n1ck-guo\n",
      "updated\n",
      "a dataset\n",
      "1 day ago\n",
      "Intel/ld_requests\n",
      "View all activity\n",
      "Articles\n",
      "Introducing AutoRound: Intel’s Advanced Quantization for LLMs and VLMs\n",
      "15 days ago\n",
      "•\n",
      "25\n",
      "Introducing HELMET\n",
      "28 days ago\n",
      "•\n",
      "26\n",
      "Accelerating LLM Inference with TGI on Intel Gaudi\n",
      "Mar 28\n",
      "•\n",
      "13\n",
      "Benchmarking Language Model Performance on 5th Gen Xeon at GCP\n",
      "Dec 17, 2024\n",
      "•\n",
      "5\n",
      "Universal Assisted Generation: Faster Decoding with Any Assistant Model\n",
      "Oct 29, 2024\n",
      "•\n",
      "55\n",
      "Faster Assisted Generation with Dynamic Speculation\n",
      "Oct 8, 2024\n",
      "•\n",
      "46\n",
      "Optimize and deploy models with Optimum-Intel and OpenVINO GenAI\n",
      "Sep 20, 2024\n",
      "•\n",
      "23\n",
      "Accelerating Protein Language Model ProtST on Intel Gaudi 2\n",
      "Jul 3, 2024\n",
      "•\n",
      "2\n",
      "Faster assisted generation support for Intel Gaudi\n",
      "Jun 4, 2024\n",
      "•\n",
      "3\n",
      "Building Cost-Efficient Enterprise RAG applications with Intel Gaudi 2 and Intel Xeon\n",
      "May 9, 2024\n",
      "•\n",
      "12\n",
      "Blazing Fast SetFit Inference with 🤗 Optimum Intel on Xeon\n",
      "Apr 3, 2024\n",
      "•\n",
      "11\n",
      "Team members\n",
      "1966\n",
      "+1932\n",
      "+1919\n",
      "+1898\n",
      "+1888\n",
      "+1868\n",
      "Organization Card\n",
      "Community\n",
      "About org cards\n",
      "Intel on Hugging Face\n",
      "Intel and Hugging Face are building powerful optimization tools to accelerate training and inference with Hugging Face libraries.\n",
      "Get started on Intel architecture with Optimum Intel and Optimum Habana\n",
      "To get started with Hugging Face Transformers software on Intel, visit the resources listed below.\n",
      "Optimum Intel\n",
      "- To deploy on Intel® Xeon, Intel® Max Series GPU, and Intel® Core Ultra, check out\n",
      "optimum-intel\n",
      ", the interface between Intel architectures and the 🤗 Transformers and Diffusers libraries. You can use these backends:\n",
      "Backend\n",
      "Installation\n",
      "OpenVINO™\n",
      "pip install --upgrade --upgrade-strategy eager \"optimum[openvino]\"\n",
      "Intel® Extension for PyTorch*\n",
      "pip install --upgrade --upgrade-strategy eager \"optimum[ipex]\"\n",
      "Intel® Neural Compressor\n",
      "pip install --upgrade --upgrade-strategy eager \"optimum[neural-compressor]\"\n",
      "Optimum Habana\n",
      "- To deploy on Intel® Gaudi® AI accelerators, check out\n",
      "optimum-habana\n",
      ", the interface between Gaudi and the 🤗 Transformers and Diffusers libraries. To install the latest stable release:\n",
      "pip install --upgrade-strategy eager optimum[habana]\n",
      "Ways to get involved\n",
      "Check out the\n",
      "Intel® Tiber™ AI Cloud\n",
      "to run your latest GenAI or LLM workload on Intel architecture.\n",
      "Want to share your model fine-tuned on Intel architecture? And for more detailed deployment tips and sample code, please visit the \"Deployment Tips\" tab from the\n",
      "Powered-by-Intel LLM Leaderboard\n",
      ".\n",
      "Join us on the\n",
      "Intel DevHub Discord\n",
      "to ask questions and interact with our AI developer community.\n",
      "Collections\n",
      "44\n",
      "AI PC: Text Generation\n",
      "Text generation LLMs that have been validated to run on the AI PC Intel® Core™ Ultra CPU and iGPU.\n",
      "OpenVINO/Mixtral-8x7B-Instruct-v0.1-int8-ov\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Nov 5, 2024\n",
      "•\n",
      "46\n",
      "•\n",
      "4\n",
      "OpenVINO/mixtral-8x7b-instruct-v0.1-int4-ov\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Nov 5, 2024\n",
      "•\n",
      "26\n",
      "•\n",
      "4\n",
      "OpenVINO/phi-2-fp16-ov\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Nov 5, 2024\n",
      "•\n",
      "110\n",
      "•\n",
      "1\n",
      "OpenVINO/phi-2-int8-ov\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Oct 29, 2024\n",
      "•\n",
      "25\n",
      "AI PC: Text-to-Image\n",
      "Text-to-image models that have been validated to run on the AI PC Intel® Core™ Ultra CPU and iGPU.\n",
      "OpenVINO/stable-diffusion-v1-5-fp16-ov\n",
      "Updated\n",
      "Feb 11\n",
      "•\n",
      "1\n",
      "OpenVINO/stable-diffusion-v1-5-int8-ov\n",
      "Updated\n",
      "Feb 11\n",
      "•\n",
      "4\n",
      "OpenVINO/LCM_Dreamshaper_v7-fp16-ov\n",
      "Updated\n",
      "Feb 11\n",
      "•\n",
      "3\n",
      "OpenVINO/LCM_Dreamshaper_v7-int8-ov\n",
      "Updated\n",
      "Feb 11\n",
      "•\n",
      "3\n",
      "Expand 44 collections\n",
      "spaces\n",
      "16\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "pinned\n",
      "Running\n",
      "2\n",
      "Synthetic Data Generator\n",
      "⚗\n",
      "Create synthetic datasets for AI applications\n",
      "Intel\n",
      "Apr 6\n",
      "pinned\n",
      "Running\n",
      "7\n",
      "UnlearnDiffAtk Benchmark\n",
      "🥇\n",
      "Browse and filter AI model evaluation results\n",
      "Intel\n",
      "Feb 4\n",
      "pinned\n",
      "Running\n",
      "171\n",
      "Low-bit Quantized Open LLM Leaderboard\n",
      "🏆\n",
      "Track, rank and evaluate open LLMs and chatbots\n",
      "Intel\n",
      "Dec 23, 2024\n",
      "Running\n",
      "1\n",
      "Intel® AI for Enterprise Inference\n",
      "📚\n",
      "LLM Chatbot on Denvr Dataworks and Intel Gaudi\n",
      "Intel\n",
      "15 days ago\n",
      "Running\n",
      "VacAIgent\n",
      "🐨\n",
      "Let AI agents plan your next vacation!\n",
      "Intel\n",
      "22 days ago\n",
      "Build error\n",
      "4\n",
      "Intel Xai Tools Cam Demo\n",
      "😻\n",
      "Intel\n",
      "Mar 9\n",
      "Expand\n",
      "\t\t\t\t\t\t\t16\n",
      "\t\t\t\t\t\t\t\tspaces\n",
      "models\n",
      "221\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "Intel/Qwen2-0.5B-Instruct-int4-sym-AutoRound\n",
      "Updated\n",
      "1 day ago\n",
      "Intel/tiny-random-mistral_ipex_model\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "14 days ago\n",
      "•\n",
      "162\n",
      "Intel/whisper-medium-openvino-fp16\n",
      "Automatic Speech Recognition\n",
      "•\n",
      "Updated\n",
      "Feb 27\n",
      "•\n",
      "1\n",
      "Intel/polite-guard\n",
      "Text Classification\n",
      "•\n",
      "Updated\n",
      "Feb 24\n",
      "•\n",
      "659\n",
      "•\n",
      "11\n",
      "Intel/versatile_audio_super_resolution_openvino\n",
      "Updated\n",
      "Dec 11, 2024\n",
      "•\n",
      "1\n",
      "Intel/tiny-random-gpt2_ipex_model\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Dec 3, 2024\n",
      "•\n",
      "899\n",
      "Intel/tiny-random-falcon_ipex_model\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Dec 3, 2024\n",
      "•\n",
      "876\n",
      "Intel/tiny-random-bert_ipex_model\n",
      "Question Answering\n",
      "•\n",
      "Updated\n",
      "Dec 3, 2024\n",
      "•\n",
      "801\n",
      "Intel/tiny-random-vit_ipex_model\n",
      "Image Classification\n",
      "•\n",
      "Updated\n",
      "Dec 3, 2024\n",
      "•\n",
      "775\n",
      "Intel/tiny-random-falcon\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Dec 2, 2024\n",
      "•\n",
      "4.47k\n",
      "Expand\n",
      "\t\t\t\t\t\t\t221\n",
      "\t\t\t\t\t\t\t\tmodels\n",
      "datasets\n",
      "21\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "Intel/ld_requests\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "133\n",
      "•\n",
      "3\n",
      "Intel/Uncovering_LVLM_Bias\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "8 days ago\n",
      "•\n",
      "54.5M\n",
      "•\n",
      "81\n",
      "Intel/NeuroComparatives\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "22 days ago\n",
      "•\n",
      "8.71M\n",
      "•\n",
      "88\n",
      "Intel/AI-Peer-Review-Detection\n",
      "Updated\n",
      "Feb 25\n",
      "•\n",
      "18\n",
      "Intel/dynamic_model_information\n",
      "Updated\n",
      "Feb 12\n",
      "•\n",
      "34\n",
      "Intel/polite-guard\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jan 16\n",
      "•\n",
      "100k\n",
      "•\n",
      "217\n",
      "•\n",
      "12\n",
      "Intel/fivl-instruct\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Dec 18, 2024\n",
      "•\n",
      "1.22M\n",
      "•\n",
      "117\n",
      "Intel/Video_Summarization_For_Retail\n",
      "Updated\n",
      "Jul 8, 2024\n",
      "•\n",
      "33\n",
      "Intel/ld_results\n",
      "Updated\n",
      "Jun 6, 2024\n",
      "•\n",
      "18\n",
      "•\n",
      "1\n",
      "Intel/SocialCounterfactuals\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Mar 28, 2024\n",
      "•\n",
      "171k\n",
      "•\n",
      "1.77k\n",
      "•\n",
      "11\n",
      "Expand\n",
      "\t\t\t\t\t\t\t21\n",
      "\t\t\t\t\t\t\t\tdatasets\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "Webpage Title:\n",
      "microsoft (Microsoft)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Microsoft\n",
      "company\n",
      "Verified\n",
      "https://www.microsoft.com/en-us/research/\n",
      "microsoft\n",
      "Activity Feed\n",
      "Follow\n",
      "12,305\n",
      "AI & ML interests\n",
      "None defined yet.\n",
      "Recent Activity\n",
      "hawk31\n",
      "new\n",
      "activity\n",
      "about 1 hour ago\n",
      "microsoft/bioemu:\n",
      "jjimenezluna/bioemu-rev\n",
      "jw2yang\n",
      "updated\n",
      "a model\n",
      "1 day ago\n",
      "microsoft/Magma-8B\n",
      "caburact\n",
      "published\n",
      "a dataset\n",
      "5 days ago\n",
      "microsoft/lost_in_conversation\n",
      "View all activity\n",
      "Team members\n",
      "254\n",
      "+220\n",
      "+207\n",
      "+186\n",
      "+176\n",
      "+156\n",
      "Collections\n",
      "18\n",
      "Phi-4\n",
      "Phi-4 family of small language, multi-modal and reasoning models.\n",
      "microsoft/Phi-4-mini-reasoning\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "14.6k\n",
      "•\n",
      "142\n",
      "microsoft/Phi-4-reasoning\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "8.38k\n",
      "•\n",
      "171\n",
      "microsoft/Phi-4-reasoning-plus\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "14.4k\n",
      "•\n",
      "246\n",
      "microsoft/Phi-4-multimodal-instruct\n",
      "Automatic Speech Recognition\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "292k\n",
      "•\n",
      "1.39k\n",
      "Phi-3\n",
      "Phi-3 family of small language and multi-modal models. Language models are available in short- and long-context lengths.\n",
      "microsoft/Phi-3.5-mini-instruct\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Mar 2\n",
      "•\n",
      "331k\n",
      "•\n",
      "•\n",
      "866\n",
      "microsoft/Phi-3.5-MoE-instruct\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Mar 7\n",
      "•\n",
      "37k\n",
      "•\n",
      "•\n",
      "558\n",
      "microsoft/Phi-3.5-vision-instruct\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "Sep 26, 2024\n",
      "•\n",
      "522k\n",
      "•\n",
      "•\n",
      "681\n",
      "microsoft/Phi-3-mini-4k-instruct\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Sep 20, 2024\n",
      "•\n",
      "618k\n",
      "•\n",
      "•\n",
      "1.19k\n",
      "Expand 18 collections\n",
      "spaces\n",
      "23\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "pinned\n",
      "Running\n",
      "12\n",
      "MageBench Leaderboard\n",
      "🥇\n",
      "This is a leaderboard for magebench\n",
      "microsoft\n",
      "Jan 17\n",
      "Running\n",
      "32\n",
      "PhineSpeechTranslator\n",
      "👀\n",
      "Break the language barrier\n",
      "microsoft\n",
      "Apr 9\n",
      "Build error\n",
      "8\n",
      "StoriesComeAlive\n",
      "🏆\n",
      "Transform handwritten moments into spoken memories\n",
      "microsoft\n",
      "Apr 9\n",
      "Build error\n",
      "28\n",
      "ThoughtsOrganizer\n",
      "🔥\n",
      "Transform your spoken thoughts into organized insights\n",
      "microsoft\n",
      "Apr 9\n",
      "Running\n",
      "107\n",
      "Phi 4 Multimodal\n",
      "🌖\n",
      "Interact with an AI by sending text, images, or audio\n",
      "microsoft\n",
      "Apr 9\n",
      "Running\n",
      "37\n",
      "Phi 4 Mini\n",
      "🌍\n",
      "Demos for Phi-4-mini-instruct model\n",
      "microsoft\n",
      "Mar 12\n",
      "Expand\n",
      "\t\t\t\t\t\t\t23\n",
      "\t\t\t\t\t\t\t\tspaces\n",
      "models\n",
      "374\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "microsoft/Magma-8B\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "5.49k\n",
      "•\n",
      "385\n",
      "microsoft/Phi-4-reasoning-plus\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "14.4k\n",
      "•\n",
      "246\n",
      "microsoft/Phi-4-reasoning\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "8.38k\n",
      "•\n",
      "171\n",
      "microsoft/phi-4-gguf\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "27.3k\n",
      "•\n",
      "135\n",
      "microsoft/MAI-DS-R1\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "8 days ago\n",
      "•\n",
      "10.4k\n",
      "•\n",
      "261\n",
      "microsoft/Phi-4-mini-instruct\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "442k\n",
      "•\n",
      "471\n",
      "microsoft/Phi-4-multimodal-instruct\n",
      "Automatic Speech Recognition\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "292k\n",
      "•\n",
      "1.39k\n",
      "microsoft/Phi-4-mini-reasoning\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "14.6k\n",
      "•\n",
      "142\n",
      "microsoft/bitnet-b1.58-2B-4T-gguf\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "38.9k\n",
      "•\n",
      "165\n",
      "microsoft/bitnet-b1.58-2B-4T-bf16\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "3.89k\n",
      "•\n",
      "26\n",
      "Expand\n",
      "\t\t\t\t\t\t\t374\n",
      "\t\t\t\t\t\t\t\tmodels\n",
      "datasets\n",
      "56\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "microsoft/lost_in_conversation\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "133\n",
      "•\n",
      "5\n",
      "microsoft/CoSAlign-Test\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "9 days ago\n",
      "•\n",
      "3.2k\n",
      "•\n",
      "132\n",
      "•\n",
      "2\n",
      "microsoft/CoSAlign-Train\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "9 days ago\n",
      "•\n",
      "125k\n",
      "•\n",
      "126\n",
      "microsoft/echelon-original-ja-main_and_right_wrist\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "14 days ago\n",
      "•\n",
      "5.83k\n",
      "•\n",
      "95\n",
      "•\n",
      "1\n",
      "microsoft/echelon-original-eef-main_right_wrist\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "15 days ago\n",
      "•\n",
      "5.83k\n",
      "•\n",
      "199\n",
      "•\n",
      "3\n",
      "microsoft/ChatBench\n",
      "Preview\n",
      "•\n",
      "Updated\n",
      "16 days ago\n",
      "•\n",
      "321\n",
      "•\n",
      "7\n",
      "microsoft/FEA-Bench\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "23 days ago\n",
      "•\n",
      "1.4k\n",
      "•\n",
      "106\n",
      "•\n",
      "4\n",
      "microsoft/BiomedParseData\n",
      "Preview\n",
      "•\n",
      "Updated\n",
      "24 days ago\n",
      "•\n",
      "164\n",
      "•\n",
      "45\n",
      "microsoft/CoSApien\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "24 days ago\n",
      "•\n",
      "200\n",
      "•\n",
      "170\n",
      "•\n",
      "1\n",
      "microsoft/WildFeedback\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Mar 25\n",
      "•\n",
      "1.06M\n",
      "•\n",
      "221\n",
      "•\n",
      "14\n",
      "Expand\n",
      "\t\t\t\t\t\t\t56\n",
      "\t\t\t\t\t\t\t\tdatasets\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "Webpage Title:\n",
      "grammarly (Grammarly)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Grammarly\n",
      "Enterprise\n",
      "company\n",
      "Verified\n",
      "https://www.grammarly.com/\n",
      "grammarly\n",
      "Activity Feed\n",
      "Follow\n",
      "160\n",
      "AI & ML interests\n",
      "None defined yet.\n",
      "Recent Activity\n",
      "machineteacher\n",
      "authored\n",
      "a paper\n",
      "14 days ago\n",
      "Toward Evaluative Thinking: Meta Policy Optimization with Evolving\n",
      "  Reward Models\n",
      "machineteacher\n",
      "updated\n",
      "a model\n",
      "3 months ago\n",
      "grammarly/spivavtor-xxl\n",
      "machineteacher\n",
      "updated\n",
      "a model\n",
      "3 months ago\n",
      "grammarly/spivavtor-large\n",
      "View all activity\n",
      "Team members\n",
      "46\n",
      "+12\n",
      "Collections\n",
      "3\n",
      "CoEdIT\n",
      "Collection of the publicly available CoEdIT dataset and instruction-tuned models for text editing.\n",
      "CoEdIT: Text Editing by Task-Specific Instruction Tuning\n",
      "Paper\n",
      "•\n",
      "2305.09857\n",
      "•\n",
      "Published\n",
      "May 17, 2023\n",
      "•\n",
      "7\n",
      "grammarly/coedit-large\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 28, 2024\n",
      "•\n",
      "21.4k\n",
      "•\n",
      "140\n",
      "grammarly/coedit-xl\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 28, 2024\n",
      "•\n",
      "288\n",
      "•\n",
      "9\n",
      "grammarly/coedit-xxl\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 28, 2024\n",
      "•\n",
      "133\n",
      "•\n",
      "32\n",
      "mEdIT\n",
      "Collection of the publicly available mEdIT dataset and instruction-tuned models for multilingual text revision.\n",
      "grammarly/medit\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Oct 1, 2024\n",
      "•\n",
      "113k\n",
      "•\n",
      "103\n",
      "•\n",
      "13\n",
      "grammarly/medit-xl\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Jun 28, 2024\n",
      "•\n",
      "5\n",
      "grammarly/medit-xxl\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Jun 28, 2024\n",
      "•\n",
      "11\n",
      "Expand 3 collections\n",
      "models\n",
      "10\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "grammarly/spivavtor-xxl\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Feb 5\n",
      "•\n",
      "10\n",
      "•\n",
      "4\n",
      "grammarly/spivavtor-large\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Feb 5\n",
      "•\n",
      "139\n",
      "•\n",
      "9\n",
      "grammarly/medit-xxl\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Jun 28, 2024\n",
      "•\n",
      "11\n",
      "grammarly/medit-xl\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Jun 28, 2024\n",
      "•\n",
      "5\n",
      "grammarly/coedit-xxl\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 28, 2024\n",
      "•\n",
      "133\n",
      "•\n",
      "32\n",
      "grammarly/coedit-xl\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 28, 2024\n",
      "•\n",
      "288\n",
      "•\n",
      "9\n",
      "grammarly/coedit-large\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 28, 2024\n",
      "•\n",
      "21.4k\n",
      "•\n",
      "140\n",
      "grammarly/coedit-xl-composite\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Oct 5, 2023\n",
      "•\n",
      "24\n",
      "•\n",
      "19\n",
      "grammarly/pseudonymization-seq2seq\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Aug 31, 2023\n",
      "•\n",
      "5\n",
      "grammarly/detexd-roberta-base\n",
      "Text Classification\n",
      "•\n",
      "Updated\n",
      "Jul 10, 2023\n",
      "•\n",
      "204\n",
      "•\n",
      "10\n",
      "datasets\n",
      "5\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "grammarly/spivavtor\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Feb 5\n",
      "•\n",
      "69.8k\n",
      "•\n",
      "64\n",
      "•\n",
      "3\n",
      "grammarly/medit\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Oct 1, 2024\n",
      "•\n",
      "113k\n",
      "•\n",
      "103\n",
      "•\n",
      "13\n",
      "grammarly/coedit\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Oct 21, 2023\n",
      "•\n",
      "70.8k\n",
      "•\n",
      "1.15k\n",
      "•\n",
      "72\n",
      "grammarly/pseudonymization-data\n",
      "Preview\n",
      "•\n",
      "Updated\n",
      "Aug 23, 2023\n",
      "•\n",
      "324\n",
      "•\n",
      "1\n",
      "grammarly/detexd-benchmark\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jul 10, 2023\n",
      "•\n",
      "1.02k\n",
      "•\n",
      "44\n",
      "•\n",
      "2\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "Webpage Title:\n",
      "Writer (Writer)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "Verified\n",
      "https://writer.com/\n",
      "Get_Writer\n",
      "writer\n",
      "Activity Feed\n",
      "Follow\n",
      "267\n",
      "AI & ML interests\n",
      "AGI, LLMs, Knowledge Graph, Palmyra, Domain Specific LLM\n",
      "Recent Activity\n",
      "kiranr\n",
      "updated\n",
      "a model\n",
      "5 days ago\n",
      "Writer/colab\n",
      "melisa\n",
      "authored\n",
      "a paper\n",
      "about 2 months ago\n",
      "Expect the Unexpected: FailSafe Long Context QA for Finance\n",
      "melisa\n",
      "updated\n",
      "a model\n",
      "2 months ago\n",
      "Writer/colab\n",
      "View all activity\n",
      "Team members\n",
      "122\n",
      "+88\n",
      "+75\n",
      "+54\n",
      "+44\n",
      "+24\n",
      "Organization Card\n",
      "Community\n",
      "About org cards\n",
      "Transform work with full-stack generative AI\n",
      "Build generative AI into any business process with the secure enterprise platform.\n",
      "Collections\n",
      "2\n",
      "Palmyra (apache 2.0 license)\n",
      "Writer/palmyra-small\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Sep 1, 2023\n",
      "•\n",
      "149\n",
      "•\n",
      "20\n",
      "Writer/palmyra-20b-chat\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Aug 17, 2024\n",
      "•\n",
      "9\n",
      "•\n",
      "11\n",
      "Writer/palmyra-med-20b\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Aug 17, 2024\n",
      "•\n",
      "2.98k\n",
      "•\n",
      "34\n",
      "Writer/palmyra-base\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Dec 24, 2024\n",
      "•\n",
      "75\n",
      "•\n",
      "44\n",
      "Palmyra (Writer license)\n",
      "Palmyra LLMs under Writer license https://writer.com/legal/open-model-license/\n",
      "Writer/Palmyra-Med-70B-32K\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Oct 1, 2024\n",
      "•\n",
      "207\n",
      "•\n",
      "109\n",
      "Writer/Palmyra-Med-70B\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Oct 1, 2024\n",
      "•\n",
      "53\n",
      "•\n",
      "81\n",
      "spaces\n",
      "3\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "Running\n",
      "9\n",
      "Financial LLM Performance Leaderboard\n",
      "📈\n",
      "Expect the Unexpected: FailSafe Long Context QA for Finance\n",
      "Writer\n",
      "Feb 19\n",
      "Sleeping\n",
      "6\n",
      "Token Counter\n",
      "📈\n",
      "Count tokens for different models\n",
      "Writer\n",
      "Nov 1, 2024\n",
      "Running\n",
      "4\n",
      "Paste To Markdown\n",
      "👁\n",
      "Convert text to Markdown\n",
      "Writer\n",
      "May 12, 2023\n",
      "models\n",
      "21\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "Writer/colab\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "2\n",
      "Writer/Palmyra-local-1_7B\n",
      "Updated\n",
      "Apr 7\n",
      "•\n",
      "5\n",
      "•\n",
      "1\n",
      "Writer/palmyra-large\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Feb 25\n",
      "•\n",
      "57\n",
      "•\n",
      "23\n",
      "Writer/palmyra-vision-dummy-weights\n",
      "Updated\n",
      "Jan 28\n",
      "Writer/bdiff-test\n",
      "Updated\n",
      "Jan 17\n",
      "Writer/palmyra-base\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Dec 24, 2024\n",
      "•\n",
      "75\n",
      "•\n",
      "44\n",
      "Writer/palmyra-creative-dummy-weights\n",
      "Updated\n",
      "Dec 18, 2024\n",
      "Writer/palmyra-x-4.3-long-cite\n",
      "Updated\n",
      "Dec 13, 2024\n",
      "Writer/palmyra-x-004-dummy-weights\n",
      "Updated\n",
      "Dec 6, 2024\n",
      "Writer/Palmyra-X-4.3-73B\n",
      "Updated\n",
      "Nov 8, 2024\n",
      "•\n",
      "1.54k\n",
      "•\n",
      "1\n",
      "Expand\n",
      "\t\t\t\t\t\t\t21\n",
      "\t\t\t\t\t\t\t\tmodels\n",
      "datasets\n",
      "6\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "Writer/FailSafeQA\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Feb 13\n",
      "•\n",
      "220\n",
      "•\n",
      "347\n",
      "•\n",
      "8\n",
      "Writer/writing-in-the-margins-multihoprag\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Sep 5, 2024\n",
      "•\n",
      "1k\n",
      "•\n",
      "21\n",
      "Writer/TinyStoriesInstruct-v0-32k-0.2\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jul 13, 2024\n",
      "•\n",
      "15.7k\n",
      "•\n",
      "61\n",
      "•\n",
      "3\n",
      "Writer/TinyStoriesInstruct-v0-32k-0.1\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jul 13, 2024\n",
      "•\n",
      "15.7k\n",
      "•\n",
      "100\n",
      "Writer/omniact\n",
      "Updated\n",
      "Apr 29, 2024\n",
      "•\n",
      "482\n",
      "•\n",
      "36\n",
      "Writer/Palmyra-instract-30\n",
      "Preview\n",
      "•\n",
      "Updated\n",
      "Sep 30, 2023\n",
      "•\n",
      "3\n",
      "•\n",
      "1\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_all_details(\"https://huggingface.co\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7f5584b-46f7-499e-aa6e-771c0d5e6a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown. Include details of company culture, customers and careers/jobs if you have the information.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e731e164-c55e-4b1f-aded-a0c473084ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; \\\n",
    "    use this information to build a short brochure of the company in markdown. \\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5_000]  # Obcięcie, jeśli więcej niż 5000 znaków\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d0203-3e25-4a0a-b70d-d4f477a58e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8093ab5e-1441-416e-a63b-78c405bdf6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = ollama.chat(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ],\n",
    "    )\n",
    "    result = response['message']['content']\n",
    "    #result = result.strip()\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caae5657-088e-4849-91e3-8e08077cd9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9872017-e2aa-442d-acf9-d72d26da5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = ollama.chat(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        result += chunk['message']['content'] or \"\"\n",
    "        #result = result.strip()\n",
    "        result = result.replace(\"```\", \" \").replace(\"markdown\", \" \")\n",
    "        update_display(Markdown(result), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ace50-0ef2-4f72-853e-47fd069ecc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90376f81-3d1c-4334-be1f-72824bc1ba2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2675785182.py, line 31)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mirrelevant.deUsunąłem linijkę z błędem, ponieważ nie była poprawnie sformatowana:\u001b[39m\n                          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import socket\n",
    "from requests.exceptions import ConnectionError, MissingSchema, InvalidSchema\n",
    "from urllib3.exceptions import MaxRetryError, NameResolutionError\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import ollama\n",
    "\n",
    "load_dotenv(override=True)\n",
    "MODEL = 'gemma3'\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            self.body = response.content\n",
    "            soup = BeautifulSoup(self.body, 'html.parser')\n",
    "            self.title = soup.title.string if soup.title else \"No title found\"\n",
    "            if soup.body:\n",
    "                for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                    irrelevant.decompose()\n",
    "                self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "            else:\n",
    "                self.text = \"\"\n",
    "            links = [link.get('href') for link in soup.find_all('a') if link.get('href')]\n",
    "            self.links = [link for link in links if link]\n",
    "        except Exception as e:\n",
    "            print(f\"Błąd podczas pobierania strony {url}: {e}\")\n",
    "            self.title = \"Error\"\n",
    "            self.text = \"\"\n",
    "            self.links = []\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\"\n",
    "\n",
    "link_system_prompt = \"\"\"You are provided with a list of links found on a webpage. You are able to decide which of the links would be most relevant to include in a brochure about the company, such as links to an About page, or a Company page, or Careers/Jobs pages. You should respond only in JSON, without text, object as in this example:\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in clean JSON format without text json on the beginning of the response. Do not include Terms of Service, Privacy, email links.\\nLinks (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt\n",
    "\n",
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "            ],\n",
    "            options={\"format\": \"json\"}\n",
    "        )\n",
    "        result = response['message']['content']\n",
    "        print(\"Odpowiedź modelu:\", result)\n",
    "        try:\n",
    "            content_json = json.loads(result)\n",
    "            return content_json\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Odpowiedź nie jest poprawnym JSON\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Błąd podczas komunikacji z modelem: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    try:\n",
    "        result += Website(url).get_contents()\n",
    "        links = get_links(url)\n",
    "        if links and \"links\" in links:\n",
    "            for link in links[\"links\"]:\n",
    "                try:\n",
    "                    result += Website(link[\"url\"]).get_contents()\n",
    "                except (socket.gaierror, NameResolutionError, MaxRetryError, ConnectionError, MissingSchema, InvalidSchema) as e:\n",
    "                    print(f\"Błąd dla linku {link['url']}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Błąd podczas pobierania strony {url}: {e}\")\n",
    "    return result\n",
    "\n",
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\nHere are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5000]  # Ograniczenie do 5000 znaków\n",
    "    return user_prompt\n",
    "\n",
    "def create_brochure(company_name, url, prompt_type=\"standard\"):\n",
    "    system_prompt = system_prompt if prompt_type == \"standard\" else system_prompt_humorous\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "            ],\n",
    "        )\n",
    "        result = response['message']['content']\n",
    "        display(Markdown(result))\n",
    "    except Exception as e:\n",
    "        print(f\"Błąd podczas generowania broszury: {e}\")\n",
    "\n",
    "# Test dla wyspagier.pl\n",
    "try:\n",
    "    print(\"Test 1: Standardowy prompt\")\n",
    "    create_brochure(\"Wyspa Gier\", \"https://wyspagier.pl\", prompt_type=\"standard\")\n",
    "    print(\"\\nTest 2: Humorystyczny prompt\")\n",
    "    create_brochure(\"Wyspa Gier\", \"https://wyspagier.pl\", prompt_type=\"humorous\")\n",
    "except Exception as e:\n",
    "    print(f\"Ogólny błąd: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fbb432-785e-4fc8-b0b2-ec882bc85063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
